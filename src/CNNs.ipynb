{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5408412",
   "metadata": {},
   "source": [
    "# CNNs and Image Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2f73a0",
   "metadata": {},
   "source": [
    "* Convolutional Neural Network ek aisa deep learning model hota hai jo images ko samajhne ke liye banaya gaya hai. Ye model image ke pixels se automatically pattern nikalta hai jaise edges, curves, textures ya shapes.\n",
    "\n",
    "* CNN multiple layers ka use karta hai jisse model simple feature se complex feature tak seekhta jise human vision jaise working milti hai.\n",
    "\n",
    "* Isme convolution, pooling ( that reduces the spatial dimensions (width and height) of a feature map while retaining important information ), activation aur fully connected layers milkar ek powerful pipeline banate hain jo image ko mathematical form me convert karke meaning samajhte hain.\n",
    "\n",
    "* CNN image classification, object detection, face recognition jaise tasks ke liye industry standard model ban chuka hai kyunki ye manual feature engineering ki dependency ko hata deta hai."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023762a7",
   "metadata": {},
   "source": [
    "### Why in AI/ML :\n",
    "\n",
    "* CNN images ko raw pixels se samajh leta hai isliye AI me visual tasks ke liye sabse reliable technique hai. Isse machine ko dekhna aur identify karna aata hai.\n",
    "\n",
    "* CNN ka weight sharing aur local connectivity model ko computationally fast banata hai jisse bade image datasets ko efficiently train kiya ja sakta hai.\n",
    "\n",
    "* Ye overfitting ko naturally kam karta hai kyunki ye pure image ko ekdum detail me memorize nahi karta balki general features seekhta hai.\n",
    "\n",
    "* Real world me jitna bhi computer vision ka kaam hota hai jaise medical image analysis, self driving cars, CCTV analytics, usme CNN core foundation hota hai."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb2b7aa",
   "metadata": {},
   "source": [
    "## CNN ke main components :\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4c2073",
   "metadata": {},
   "source": [
    "### # Convolution Layer :\n",
    "\n",
    "* Image ke chote chote patch par filter slide karta hai aur important pattern detect karta hai.\n",
    "\n",
    "### # Pooling Layer :\n",
    "\n",
    "* Ye image ke size ko kam karta hai taa ki model fast ho jaye. (width and height)\n",
    "\n",
    "### # Activation (ReLU) :\n",
    "\n",
    "* Negative values ko zero karta hai jisse model nonlinear ban jata hai.\n",
    "\n",
    "### # Fully Connected Layer:\n",
    "\n",
    "* Final decision yahi layer karti hai jaise dog ya cat predict karna.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1968f02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # yaha 1 = grayscale channels, 8 = filters\n",
    "        # kernel 3 means filter 3x3 patch par compute karega\n",
    "        self.conv = nn.Conv2d(1 , 8 , kernel_size=3)\n",
    "\n",
    "        # 2x2 region me maximum value choose karta hai\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # final class prediction\n",
    "        self.fc = nn.Linear(8*26*26 , 2)\n",
    "\n",
    "    def forward(self , x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79c04b8",
   "metadata": {},
   "source": [
    "# Exammple :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae1a0d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item : 1 Loss : 7.9719085693359375\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as opt\n",
    "\n",
    "model = CNN()\n",
    "loss = nn.CrossEntropyLoss()    # loss for classification\n",
    "opt = opt.Adam(model.parameters() , lr=0.0001)  # update weights\n",
    "\n",
    "# random fake images: batch=5, channel=1, size=28x28\n",
    "images = torch.randn(5 , 1 , 28 , 28)\n",
    "\n",
    "# dummy output classes\n",
    "labels = torch.tensor([0, 1, 0, 1, 0])\n",
    "\n",
    "for i in range(1):\n",
    "\n",
    "    # CNN image se feature map extract karega\n",
    "    out = model(images)\n",
    "\n",
    "    # flatten because fully connected layer me vector chahiye\n",
    "    out = out.view(out.size(0), -1)  \n",
    "\n",
    "    # predicted output aur real label ka difference\n",
    "    loss = loss(out , labels)\n",
    "\n",
    "    # gradients calculate\n",
    "    loss.backward()\n",
    "\n",
    "    # parameters update jisse model improve ho\n",
    "    opt.step()\n",
    "\n",
    "    opt.zero_grad()  \n",
    "\n",
    "    print(\"Item :\" , i+1 , \"Loss :\" , loss.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa708289",
   "metadata": {},
   "source": [
    "# Use pre-trained MobileNet or ResNet for inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322f0d68",
   "metadata": {},
   "source": [
    "### CNNs with Pre Trained MobileNet ya ResNet (Inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03833bb8",
   "metadata": {},
   "source": [
    "* Pre trained models wo hote hain jo already bade datasets par train kiye gaye hote hain jaise ImageNet. Inme million images aur thousand categories use hoti hain jisse model powerful visual features seekh leta hai.\n",
    "\n",
    "* MobileNet ek lightweight model hota hai jo mobile aur low power devices par fast inference ke liye design kiya gaya hai. Ye depthwise separable convolution use karta hai jisse speed badh jaati hai.\n",
    "\n",
    "* ResNet ek deep aur high accuracy model hota hai jo residual blocks use karta hai. Residual connections model ko 50 layer, 101 layer jaise deep networks train karne me madad karte hain bina gradient vanish ki problem ke.\n",
    "\n",
    "* Inference ka matlab hota hai ki hum model ko train nahi karte. Bas already trained model ki help se image ka output predict karte hain, jaise class, feature vector ya probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f02352",
   "metadata": {},
   "source": [
    "#### Why in AI/ML :\n",
    "\n",
    "* Pre trained models time aur compute dono bachate hain. Aapko scratch se model train nahi karna padta, fir bhi world class accuracy milti hai.\n",
    "\n",
    "* Ye models general features seekh chuke hote hain jaise edges, texture, shapes, isliye new dataset par bhi achcha perform karte hain even without training.\n",
    "\n",
    "* Inference se developer quickly prototype kar sakta hai, real time systems me deploy kar sakta hai aur production ready pipeline bana sakta hai.\n",
    "\n",
    "* Real world me CCTV analytics, healthcare, ecommerce image search, robotics sabhi me pre trained CNN models fastest aur reliable choice hote hain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2f8a09",
   "metadata": {},
   "source": [
    "### MobileNet / ResNet inference PyTorch example\n",
    "MobileNet Example :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3443195a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "\n",
    "# load pretrained model\n",
    "model = models.mobilenet_v2(weights = models.MobileNet_V2_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# eval mode kyunki hum inference kar rahe hain\n",
    "model.eval()\n",
    "\n",
    "# image preprocessing\n",
    "transform = T.Compose([\n",
    "    T.Resize(256), \n",
    "    T.CenterCrop(224),  \n",
    "    T.ToTensor(),  \n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])  \n",
    "\n",
    "img = Image.open(\"test.jpg\")\n",
    "\n",
    "# batch dimension add kiya\n",
    "img_t = transform(img).unsqueeze(0)  \n",
    "\n",
    "while torch.no_grad():\n",
    "\n",
    "    # yaha model image ka class prediction return karega\n",
    "    out = model(img_t)\n",
    "\n",
    "prob = torch.softmax(out, dim=1)\n",
    "top_class = prob.argmax().item()\n",
    "\n",
    "# final predicted class index\n",
    "print(top_class)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
