{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81ced1bf",
   "metadata": {},
   "source": [
    "# HuggingFace Basics :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ae7764",
   "metadata": {},
   "source": [
    "* HuggingFace ek open hub jaha par thousands pre trained models milte hain jo NLP tasks ke liye ready hote hain. Ye models Transformers library ke through easily load kiye jaa sakte hain aur aap bina training ke powerful results nikal sakte ho.\n",
    "\n",
    "* HuggingFace ke models jaise BERT DistilBERT RoBERTa already large text data par train hote hain isliye wo language ko deep level par samajh pate hain.\n",
    "\n",
    "* Transformers library model, tokenizer aur pipeline bhi provide karti hai jisse inference karna bahut simple ho jata hai. Ek line me aapka text classify ho sakta hai.\n",
    "\n",
    "* HuggingFace ka ecosystem CPU par bhi kaam karta hai jisse beginners ya normal laptops par bhi NLP tasks easily perform ho jate hain.\n",
    "\n",
    "* HuggingFace pipelines complex model architecture ko simple interface me convert karte hain jisse user sirf text input kare aur direct output mil jaye\n",
    "\n",
    "* Industry me text classification sentiment analysis spam detection hate speech filtering sab me HuggingFace ke ready models use hote hain.\n",
    "\n",
    "* Ye complete ecosystem hai jisme datasets models tokenizers and training scripts ek jagah available hote hain jisse developer fast experiment aur deploy kar sakta hai."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8859ff",
   "metadata": {},
   "source": [
    "### Text Classification Example with explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3968719d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_1', 'score': 0.5066815614700317}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# device -1 matlab model CPU par chal raha hai\n",
    "# pipeline automatic tokenizer aur model load kar deta hai\n",
    "classifier = pipeline(\"text-classification\" , model=\"distilbert-base-uncased\" , device=-1)\n",
    "\n",
    "text = \"I loved this movie it was amazing\"\n",
    "result = classifier(text)\n",
    "\n",
    "# yaha model text ko tokens me convert karta hai\n",
    "# phir forward pass hota hai aur output probability milti hai\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7654561e",
   "metadata": {},
   "source": [
    "* pipeline function task ka type choose karta hai jaise text classification\n",
    "\n",
    "* model CPU par load hota hai kyunki device -1 diya hai\n",
    "\n",
    "* tokenizer text ko numbers me convert karta hai jisse model process kar sake\n",
    "\n",
    "* final output me label aur confidence score milega"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffa82b0",
   "metadata": {},
   "source": [
    "### Load Model and Tokenizer Manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a415990",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2326, -0.0637]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "\n",
    "text = \"This product is really good\"\n",
    "tokens = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "# tokenizer sentence ko token ids me convert karta hai jo model ke liye input hote hain\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(**tokens)\n",
    "    # CPU par inference ho raha hai\n",
    "    # logits raw scores hote hain jisse final prediction generate hota hai\n",
    "\n",
    "print(output.logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c645b3",
   "metadata": {},
   "source": [
    "* AutoTokenizer words ko token ids me convert karta hai\n",
    "\n",
    "* AutoModel prediction ke raw scores deta hai\n",
    "\n",
    "* torch.no_grad inference mode hota hai jisme gradients off rehte hain\n",
    "\n",
    "* CPU default device hota hai isliye extra settings ki jarurat nahi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
