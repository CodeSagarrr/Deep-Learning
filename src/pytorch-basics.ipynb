{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdd763e3",
   "metadata": {},
   "source": [
    "# PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5cc50b",
   "metadata": {},
   "source": [
    "* PyTorch ek open-source deep learning framework hai jo tensor computation aur neural network banane ko simple, fast aur flexible banata hai.\n",
    "\n",
    "* Isme GPU acceleration ka support hota hai jisse large models ko train karna fast ho jata hai aur real-world AI problems ko easily handle kiya ja sakta hai.\n",
    "\n",
    "* PyTorch ka computation graph dynamic hota hai, matlab code chalate waqt graph banta hai, jisse debugging aur experimentation bahut smooth ho jata hai.\n",
    "\n",
    "* Ye python-friendly framework hai, matlab normal python code ki tarah feel hoti hai aur research, prototyping aur production sabme comfortable kaam hota hai."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958527ab",
   "metadata": {},
   "source": [
    "## Why in AI/ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ef1c92",
   "metadata": {},
   "source": [
    "* AI/ML me models ko quickly test aur modify karne ki zarurat hoti hai, PyTorch ka dynamic graph is process ko fast banata hai aur aap apne ideas fast iterate kar sakte ho.\n",
    "\n",
    "* Deep learning me GPU ka use common hai, PyTorch GPU computation ko simple .to(\"cuda\") se enable kar deta hai aur performance automatically improve ho jati hai.\n",
    "\n",
    "* AI tasks jaise NLP, Computer Vision, Reinforcement Learning me high-level modules available hote hain jo model training ko easy aur standard banate hain.\n",
    "\n",
    "* Research community ka sabse popular tool PyTorch hi hai, isliye naye papers, models aur tutorials sabse pehle PyTorch me aate hain, jo aapko industry standards ke close rakhta hai."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3a8795",
   "metadata": {},
   "source": [
    "### Important Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44430cf",
   "metadata": {},
   "source": [
    "#### 1 : Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb421b5d",
   "metadata": {},
   "source": [
    "* PyTorch ka core data structure tensor hota hai, jo numpy array jaisa hota hai lekin GPU pe run kar sakta hai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9a7b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch as t\n",
    "\n",
    "# yeh 2x2 tensor create kar raha hai float values ke sath\n",
    "tensor = t.tensor([[1, 2], [3, 4]] , dtype=t.float32)\n",
    "\n",
    "# is line se tensor ko CPU par rakha gaya, GPU ho to .to(\"cuda\") kar sakte ho\n",
    "y = tensor.to(\"cpu\")\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ba553d",
   "metadata": {},
   "source": [
    "#### 2 : Autograd (Automatic Differentiation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c854994",
   "metadata": {},
   "source": [
    "* Deep learning me gradient calculation automatic hoti hai, PyTorch ka autograd yeh kaam karta hai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4008282e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# requires_grad=True matlab gradient calculate hoga \n",
    "\n",
    "a = t.tensor(5.0 , requires_grad=True)\n",
    "\n",
    "# computation track ho rahi hai\n",
    "b = a * 3\n",
    "\n",
    "# gradient calculate kar diya\n",
    "b.backward()\n",
    "\n",
    "# isme b ka da/gradient store hota hai, result: 3\n",
    "print(a.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16aff0dd",
   "metadata": {},
   "source": [
    "#### 3 : Neural Network Module (nn.Module)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1713b3e5",
   "metadata": {},
   "source": [
    "* PyTorch me models class ke through banaye jate hain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599fd8ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleNet(\n",
       "  (fc): Linear(in_features=6, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(6 , 3)\n",
    "        # yeh layer 6 input values ko 3 output values me convert karegi\n",
    "\n",
    "    def forward(self , x):\n",
    "        return self.fc(x)   # forward pass me data layer ke through flow hota hai\n",
    "\n",
    "\n",
    "model = SimpleNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d61da17",
   "metadata": {},
   "source": [
    "#### 4 : Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a923757",
   "metadata": {},
   "source": [
    "* Model ko learn karne me optimizer help karta hai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71e57e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(model.parameters() , lr=0.01)\n",
    "# SGD ek simple learning algorithm hai\n",
    "\n",
    "optimizer.zero_grad()\n",
    "# purane gradients clear kiye\n",
    "\n",
    "# loss.backward()\n",
    "# naya gradient calculate\n",
    "\n",
    "optimizer.step() \n",
    "# weights update huye"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6ae7dc",
   "metadata": {},
   "source": [
    "#### 5 : DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02205b2a",
   "metadata": {},
   "source": [
    "* Large dataset ko batch me load karne ke liye use hota hai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c234d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x257698db990>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader , TensorDataset\n",
    "\n",
    "# dataset\n",
    "# 100 samples, 4 features\n",
    "data = t.randn(100 , 4)\n",
    "\n",
    "labels = t.randint(0 , 2 , (100,))\n",
    "# random binary labels\n",
    "\n",
    "dataset = TensorDataset(data , labels)\n",
    "loader = DataLoader(dataset , batch_size=10 , shuffle=True)\n",
    "# model ko 10 sample ek baar me milenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd30ba12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# dataset\n",
    "X = torch.randn(100, 4)  \n",
    "y = torch.randint(0, 2, (100,))  \n",
    "\n",
    "loader = DataLoader(TensorDataset(X, y), batch_size=8, shuffle=True)\n",
    "\n",
    "# model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(4, 8),  \n",
    "    nn.ReLU(),        \n",
    "    nn.Linear(8, 2)    \n",
    ")\n",
    "\n",
    "# loss + optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# training loop\n",
    "for epoch in range(5):\n",
    "    for batch_x, batch_y in loader:\n",
    "        pred = model(batch_x)  \n",
    "        # model se prediction\n",
    "\n",
    "        loss = loss_fn(pred, batch_y)  \n",
    "        # loss calculate\n",
    "\n",
    "        opt.zero_grad()  \n",
    "        # gradients reset\n",
    "\n",
    "        loss.backward()  \n",
    "        # naya gradient calculate\n",
    "\n",
    "        opt.step()  \n",
    "        # weights update\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68320d80",
   "metadata": {},
   "source": [
    "#### Additional Important Points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cf5f4e",
   "metadata": {},
   "source": [
    "* PyTorch ka ecosystem strong hai jisme torchvision, torchaudio, torchtext jaise ready-made libraries milti hain jo large datasets, pretrained models aur common functions provide karti hain.\n",
    "\n",
    "* Transfer learning PyTorch me bahut simple hai, pretrained models ko aap asaani se import karke apne dataset me fine-tune kar sakte ho.\n",
    "\n",
    "* Transfer learning PyTorch me bahut simple hai, pretrained models ko aap asaani se import karke apne dataset me fine-tune kar sakte ho.\n",
    "\n",
    "* PyTorch ONNX export ki help se aap model ko mobile, edge devices aur other frameworks me deploy kar sakte ho jisse real-world AI products banana easy ho jata hai."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
